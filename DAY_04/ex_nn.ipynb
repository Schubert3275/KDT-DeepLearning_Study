{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망 모델 클래스 만들기 <hr>\n",
    "\n",
    "-   부모 클래스 : nn.Module 상속 받음\n",
    "-   필수 오버라이딩 메서드 : \\_\\_init\\_\\_(), forward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 <hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀 모델 클래스 생성\n",
    "# - Linear + sigmoid\n",
    "class LogicLinear(nn.Module):\n",
    "    # 모델 구조 설정\n",
    "    def __init__(self, in_, out_):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_, 10)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.layer2 = nn.Linear(10, out_)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "\n",
    "    # 순방향 학습 진행 콜백함수\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        z = self.sigmoid1(y)\n",
    "        y = self.layer2(z)\n",
    "        z = self.sigmoid2(y)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조 확인 ====>\n",
      "LogicLinear(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (sigmoid1): Sigmoid()\n",
      "  (layer2): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (sigmoid2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ll = LogicLinear(784, 3)\n",
    "print(f\"모델 구조 확인 ====>\\n{ll}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델구성 W, b ====>\n",
      "Parameter containing:\n",
      "tensor([[-0.0210, -0.0260, -0.0137,  ..., -0.0195, -0.0245, -0.0265],\n",
      "        [ 0.0261, -0.0195,  0.0286,  ...,  0.0237, -0.0272,  0.0190],\n",
      "        [ 0.0238,  0.0270, -0.0003,  ..., -0.0068, -0.0331, -0.0316],\n",
      "        ...,\n",
      "        [ 0.0213, -0.0113, -0.0217,  ..., -0.0151,  0.0276,  0.0248],\n",
      "        [-0.0204, -0.0132, -0.0047,  ...,  0.0056, -0.0264,  0.0104],\n",
      "        [ 0.0033,  0.0316, -0.0210,  ..., -0.0156,  0.0279,  0.0094]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0147,  0.0121,  0.0187,  0.0307, -0.0187,  0.0105, -0.0084, -0.0148,\n",
      "        -0.0147, -0.0260], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0355, -0.2211,  0.0203, -0.3026,  0.1681,  0.1947,  0.1003,  0.2202,\n",
      "         -0.0950,  0.0385],\n",
      "        [-0.0658, -0.2728,  0.0157,  0.1412,  0.1450,  0.0032,  0.2253, -0.2148,\n",
      "          0.0935, -0.2027],\n",
      "        [-0.1965,  0.1119,  0.0830, -0.0959, -0.1037, -0.1337,  0.2691,  0.1109,\n",
      "          0.1934, -0.0356]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0044,  0.1033,  0.2517], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"모델구성 W, b ====>\")\n",
    "for param in ll.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
