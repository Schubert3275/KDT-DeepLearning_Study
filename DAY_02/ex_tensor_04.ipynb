{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor shape 변경\n",
    "\n",
    "-   reshape(), view() : 원소 개수가 유지됨!, 기존 텐서 공유함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 데이터 생성\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim)\n",
    "print(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 3] ===> [3, 2] 형태 변경 : 원소 동일 6개\n",
    "t1.view(3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 3] ===> [6, 1] 형태 변경 : 원소 동일 6개\n",
    "t1.view(6, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 3] ===> [6, 1] 형태 변경 : 원소 동일 6개\n",
    "# -1 : 원소 수를 알아서 행에 할당\n",
    "t1.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 3] ===> [6, 1] 형태 변경 : 원소 동일 6개\n",
    "# -1 : 원소 수를 알아서 열에 할당\n",
    "t1.view(6, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor.reshape()\n",
    "t1.reshape(-1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원소 수 유지되어야 함!\n",
    "# RuntimeError: shape '[-1, 7]' is invalid for input of size 6\n",
    "# t1.reshape(-1, 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   전치 : 열<->행 형 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2]) False\n"
     ]
    }
   ],
   "source": [
    "print(t1.shape)\n",
    "\n",
    "t2 = t1.T\n",
    "print(t2.shape, t2.is_contiguous())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeError: view size is not compatible with input tensor's size and stride\n",
    "# t2.view(-1, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 2, 5, 3, 6]]) True\n"
     ]
    }
   ],
   "source": [
    "t3 = t2.reshape(-1, 6)\n",
    "print(t3, t3.is_contiguous())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 데이터의 메모리 저장 정보 즉 메타데이터\n",
    "\n",
    "-   현재 저장 형태, 검색 방향 정보, 시작 정보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) 2\n",
      "t1.storage() =>  1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t1.storage_offset() => 0\n",
      "t1.stride() => (3, 1)\n",
      "t1.is_contiguous() => True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-25\\AppData\\Local\\Temp\\ipykernel_6404\\3362085813.py:3: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  print(f't1.storage() => {t1.storage()}')\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1.shape, t1.ndim)\n",
    "print(f't1.storage() => {t1.storage()}')\n",
    "print(f't1.storage_offset() => {t1.storage_offset()}')\n",
    "print(f't1.stride() => {t1.stride()}')\n",
    "print(f't1.is_contiguous() => {t1.is_contiguous()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2.storage() =>  1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t2.storage_offset() => 0\n",
      "t2.stride() => (2, 1)\n",
      "t2.is_contiguous() => True\n"
     ]
    }
   ],
   "source": [
    "t2 = t1.view(-1, 2)\n",
    "print(f't2.storage() => {t2.storage()}')\n",
    "print(f't2.storage_offset() => {t2.storage_offset()}')\n",
    "print(f't2.stride() => {t2.stride()}')\n",
    "print(f't2.is_contiguous() => {t2.is_contiguous()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3.storage() =>  1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t3.storage_offset() => 0\n",
      "t3.stride() => (1, 3)\n",
      "t3.is_contiguous() => False\n",
      "3977466876480 3977466876480 3977466876488\n"
     ]
    }
   ],
   "source": [
    "t3 = t1.T\n",
    "print(f't3.storage() => {t3.storage()}')\n",
    "print(f't3.storage_offset() => {t3.storage_offset()}')\n",
    "print(f't3.stride() => {t3.stride()}')\n",
    "print(f't3.is_contiguous() => {t3.is_contiguous()}')\n",
    "print(t3.data_ptr(), t3[0].data_ptr(), t3[1].data_ptr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t4.storage() =>  1\n",
      " 4\n",
      " 2\n",
      " 5\n",
      " 3\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t4.storage_offset() => 0\n",
      "t4.stride() => (2, 1)\n",
      "t4.is_contiguous() => True\n",
      "3977466876544 3977466876544 3977466876560\n"
     ]
    }
   ],
   "source": [
    "t4 = t3.contiguous()\n",
    "print(f't4.storage() => {t4.storage()}')\n",
    "print(f't4.storage_offset() => {t4.storage_offset()}')\n",
    "print(f't4.stride() => {t4.stride()}')\n",
    "print(f't4.is_contiguous() => {t4.is_contiguous()}')\n",
    "print(t4.data_ptr(), t4[0].data_ptr(), t4[1].data_ptr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5.storage() =>  1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
      "t5.storage_offset() => 0\n",
      "t5.stride() => (3, 1)\n",
      "t5.is_contiguous() => True\n",
      "3977466876480 3977466876480 3977466876504\n"
     ]
    }
   ],
   "source": [
    "t5 = t3.T\n",
    "print(f't5.storage() => {t5.storage()}')\n",
    "print(f't5.storage_offset() => {t5.storage_offset()}')\n",
    "print(f't5.stride() => {t5.stride()}')\n",
    "print(f't5.is_contiguous() => {t5.is_contiguous()}')\n",
    "print(t5.data_ptr(), t5[0].data_ptr(), t5[1].data_ptr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 제거/추가\n",
    "\n",
    "-   tensor.squeeze() : 텐서에서 차원이 1인 것 제거\n",
    "-   tensor.unsqueeze(dim) : 텐서에 차원 1인 것 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "t1 = torch.tensor([[1, 2], [3, 4]])\n",
    "t2 = torch.tensor([[1,2,3,4]])\n",
    "t3 = torch.tensor([[[1,2,3,4]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 => torch.Size([2, 2]), 2D, 3977466937344\n",
      "t2 => torch.Size([1, 4]), 2D, 3977466937472\n",
      "t3 => torch.Size([1, 1, 4]), 3D, 3977466937536\n"
     ]
    }
   ],
   "source": [
    "print(f't1 => {t1.shape}, {t1.ndim}D, {t1.data_ptr()}')\n",
    "print(f't2 => {t2.shape}, {t2.ndim}D, {t2.data_ptr()}')\n",
    "print(f't3 => {t3.shape}, {t3.ndim}D, {t3.data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 차원 축소 => torch.Size([2, 2]), 2D, 3977466937344\n",
      "t2 차원 축소 => torch.Size([4]), 1D, 3977466937472\n",
      "t3 차원 축소 => torch.Size([4]), 1D, 3977466937536\n",
      "t3 차원 축소 => torch.Size([1, 4]), 2D, 3977466937536\n",
      "t3 차원 축소 => torch.Size([1, 1, 4]), 3D, 3977466937536\n"
     ]
    }
   ],
   "source": [
    "t11 = t1.squeeze()\n",
    "t22 = t2.squeeze()\n",
    "t33 = t3.squeeze()\n",
    "t44 = t3.squeeze(0)\n",
    "t55 = t3.squeeze(2)  # dim => shape index\n",
    "print(f't1 차원 축소 => {t11.shape}, {t11.ndim}D, {t11.data_ptr()}')\n",
    "print(f't2 차원 축소 => {t22.shape}, {t22.ndim}D, {t22.data_ptr()}')\n",
    "print(f't3 차원 축소 => {t33.shape}, {t33.ndim}D, {t33.data_ptr()}')\n",
    "print(f't3 차원 축소 => {t44.shape}, {t44.ndim}D, {t44.data_ptr()}')\n",
    "print(f't3 차원 축소 => {t55.shape}, {t55.ndim}D, {t55.data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 정보 => torch.Size([2, 2]), 2D, 3977466937344, (2, 1)\n"
     ]
    }
   ],
   "source": [
    "## 원소/요소 수 변경 없이 1차원 증가시키기 => torch.unsqueeze(dim)\n",
    "print(f't1 정보 => {t1.shape}, {t1.ndim}D, {t1.data_ptr()}, {t11.stride()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 차원 추가 => torch.Size([1, 2, 2]), 3D, 3977466937344, (4, 2, 1)\n",
      "t1 차원 추가 => torch.Size([2, 2, 1]), 3D, 3977466937344, (2, 1, 1)\n",
      "t1 차원 추가 => torch.Size([2, 1, 2]), 3D, 3977466937344, (2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "t11 = t1.unsqueeze(dim=0)\n",
    "t22 = t1.unsqueeze(dim=-1)\n",
    "t33 = t1.unsqueeze(dim=1)\n",
    "print(f't1 차원 추가 => {t11.shape}, {t11.ndim}D, {t11.data_ptr()}, {t11.stride()}')\n",
    "print(f't1 차원 추가 => {t22.shape}, {t22.ndim}D, {t22.data_ptr()}, {t22.stride()}')\n",
    "print(f't1 차원 추가 => {t33.shape}, {t33.ndim}D, {t33.data_ptr()}, {t33.stride()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 차원/형태 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 => torch.Size([1, 3, 2]), 3D, (6, 2, 1), True, 3977466878336, 3977466878336\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[[1, 2], [11, 22], [44, 55]]])\n",
    "\n",
    "print(f't1 => {t1.shape}, {t1.ndim}D, {t1.stride()}, {t1.is_contiguous()}, {t1.data_ptr()}, {t1[0].data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t11 => torch.Size([2, 3, 1]), 3D, (1, 2, 6), False, 3977466877440, 3977466877440\n"
     ]
    }
   ],
   "source": [
    "# 2개의 차원을 변경하는 메서드\n",
    "t11 = t1.transpose(0, 2)\n",
    "print(f't11 => {t11.shape}, {t11.ndim}D, {t11.stride()}, {t11.is_contiguous()}, {t11.data_ptr()}, {t11[0].data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t22 => torch.Size([3, 2, 1]), 3D, (2, 1, 6), True, 3977466877440, 3977466877440\n"
     ]
    }
   ],
   "source": [
    "# 모든 차원을 변경하는 메서드\n",
    "t22 = t1.permute(1, 2, 0)\n",
    "print(f't22 => {t22.shape}, {t22.ndim}D, {t22.stride()}, {t22.is_contiguous()}, {t22.data_ptr()}, {t22[0].data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t33 => torch.Size([2, 1, 3]), 3D, (1, 6, 2), False, 3977466877440, 3977466937536\n"
     ]
    }
   ],
   "source": [
    "# 모든 차원을 변경하는 메서드\n",
    "t33 = t1.permute(2, 0, 1)\n",
    "print(f't33 => {t33.shape}, {t33.ndim}D, {t33.stride()}, {t33.is_contiguous()}, {t33.data_ptr()}, {t3[0].data_ptr()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[None].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
