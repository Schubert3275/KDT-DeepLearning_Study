{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../../data/text/winequality-white.csv'\n",
    "wine_np = np.loadtxt(filename, delimiter=';', skiprows=1)\n",
    "wine_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_t1 = torch.from_numpy(wine_np)\n",
    "wine_t1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 11]), torch.float32, torch.Size([4898, 1]), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = wine_t1[:, :-1].float()\n",
    "y_train = (wine_t1[:, -1] > 6).unsqueeze(1).float()\n",
    "X_train.shape, X_train.dtype, y_train.shape, y_train.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0/100000 Cost: 9.080083, Accuracy 78.36%\n",
      "Epoch : 1000/100000 Cost: 0.538148, Accuracy 76.99%\n",
      "Epoch : 2000/100000 Cost: 0.510659, Accuracy 77.50%\n",
      "Epoch : 3000/100000 Cost: 0.507126, Accuracy 77.48%\n",
      "Epoch : 4000/100000 Cost: 0.505026, Accuracy 77.54%\n",
      "Epoch : 5000/100000 Cost: 0.503552, Accuracy 77.66%\n",
      "Epoch : 6000/100000 Cost: 0.502416, Accuracy 77.75%\n",
      "Epoch : 7000/100000 Cost: 0.501467, Accuracy 77.83%\n",
      "Epoch : 8000/100000 Cost: 0.500630, Accuracy 77.87%\n",
      "Epoch : 9000/100000 Cost: 0.499862, Accuracy 77.85%\n",
      "Epoch : 10000/100000 Cost: 0.499140, Accuracy 77.85%\n",
      "Epoch : 11000/100000 Cost: 0.498451, Accuracy 77.85%\n",
      "Epoch : 12000/100000 Cost: 0.497788, Accuracy 77.83%\n",
      "Epoch : 13000/100000 Cost: 0.497147, Accuracy 77.89%\n",
      "Epoch : 14000/100000 Cost: 0.496525, Accuracy 77.89%\n",
      "Epoch : 15000/100000 Cost: 0.495920, Accuracy 77.93%\n",
      "Epoch : 16000/100000 Cost: 0.495331, Accuracy 77.93%\n",
      "Epoch : 17000/100000 Cost: 0.494758, Accuracy 77.97%\n",
      "Epoch : 18000/100000 Cost: 0.494199, Accuracy 77.97%\n",
      "Epoch : 19000/100000 Cost: 0.493655, Accuracy 77.99%\n",
      "Epoch : 20000/100000 Cost: 0.493125, Accuracy 78.01%\n",
      "Epoch : 21000/100000 Cost: 0.492608, Accuracy 78.01%\n",
      "Epoch : 22000/100000 Cost: 0.492103, Accuracy 77.99%\n",
      "Epoch : 23000/100000 Cost: 0.491612, Accuracy 78.03%\n",
      "Epoch : 24000/100000 Cost: 0.491132, Accuracy 77.99%\n",
      "Epoch : 25000/100000 Cost: 0.490664, Accuracy 77.99%\n",
      "Epoch : 26000/100000 Cost: 0.490208, Accuracy 78.01%\n",
      "Epoch : 27000/100000 Cost: 0.489763, Accuracy 78.03%\n",
      "Epoch : 28000/100000 Cost: 0.489328, Accuracy 78.05%\n",
      "Epoch : 29000/100000 Cost: 0.488905, Accuracy 78.05%\n",
      "Epoch : 30000/100000 Cost: 0.488491, Accuracy 78.07%\n",
      "Epoch : 31000/100000 Cost: 0.488087, Accuracy 78.07%\n",
      "Epoch : 32000/100000 Cost: 0.487693, Accuracy 78.07%\n",
      "Epoch : 33000/100000 Cost: 0.487308, Accuracy 78.07%\n",
      "Epoch : 34000/100000 Cost: 0.486933, Accuracy 78.09%\n",
      "Epoch : 35000/100000 Cost: 0.486566, Accuracy 78.13%\n",
      "Epoch : 36000/100000 Cost: 0.486208, Accuracy 78.13%\n",
      "Epoch : 37000/100000 Cost: 0.485858, Accuracy 78.13%\n",
      "Epoch : 38000/100000 Cost: 0.485516, Accuracy 78.17%\n",
      "Epoch : 39000/100000 Cost: 0.485183, Accuracy 78.17%\n",
      "Epoch : 40000/100000 Cost: 0.484857, Accuracy 78.20%\n",
      "Epoch : 41000/100000 Cost: 0.484538, Accuracy 78.15%\n",
      "Epoch : 42000/100000 Cost: 0.484227, Accuracy 78.15%\n",
      "Epoch : 43000/100000 Cost: 0.483922, Accuracy 78.13%\n",
      "Epoch : 44000/100000 Cost: 0.483625, Accuracy 78.17%\n",
      "Epoch : 45000/100000 Cost: 0.483334, Accuracy 78.15%\n",
      "Epoch : 46000/100000 Cost: 0.483049, Accuracy 78.15%\n",
      "Epoch : 47000/100000 Cost: 0.482771, Accuracy 78.17%\n",
      "Epoch : 48000/100000 Cost: 0.482499, Accuracy 78.15%\n",
      "Epoch : 49000/100000 Cost: 0.482233, Accuracy 78.17%\n",
      "Epoch : 50000/100000 Cost: 0.481973, Accuracy 78.20%\n",
      "Epoch : 51000/100000 Cost: 0.481718, Accuracy 78.20%\n",
      "Epoch : 52000/100000 Cost: 0.481469, Accuracy 78.22%\n",
      "Epoch : 53000/100000 Cost: 0.481225, Accuracy 78.22%\n",
      "Epoch : 54000/100000 Cost: 0.480986, Accuracy 78.26%\n",
      "Epoch : 55000/100000 Cost: 0.480753, Accuracy 78.24%\n",
      "Epoch : 56000/100000 Cost: 0.480524, Accuracy 78.22%\n",
      "Epoch : 57000/100000 Cost: 0.480300, Accuracy 78.24%\n",
      "Epoch : 58000/100000 Cost: 0.480080, Accuracy 78.24%\n",
      "Epoch : 59000/100000 Cost: 0.479865, Accuracy 78.34%\n",
      "Epoch : 60000/100000 Cost: 0.479655, Accuracy 78.36%\n",
      "Epoch : 61000/100000 Cost: 0.479449, Accuracy 78.34%\n",
      "Epoch : 62000/100000 Cost: 0.479247, Accuracy 78.36%\n",
      "Epoch : 63000/100000 Cost: 0.479049, Accuracy 78.36%\n",
      "Epoch : 64000/100000 Cost: 0.478855, Accuracy 78.32%\n",
      "Epoch : 65000/100000 Cost: 0.478664, Accuracy 78.30%\n",
      "Epoch : 66000/100000 Cost: 0.478478, Accuracy 78.34%\n",
      "Epoch : 67000/100000 Cost: 0.478295, Accuracy 78.36%\n",
      "Epoch : 68000/100000 Cost: 0.478116, Accuracy 78.36%\n",
      "Epoch : 69000/100000 Cost: 0.477940, Accuracy 78.36%\n",
      "Epoch : 70000/100000 Cost: 0.477767, Accuracy 78.38%\n",
      "Epoch : 71000/100000 Cost: 0.477598, Accuracy 78.42%\n",
      "Epoch : 72000/100000 Cost: 0.477432, Accuracy 78.40%\n",
      "Epoch : 73000/100000 Cost: 0.477268, Accuracy 78.48%\n",
      "Epoch : 74000/100000 Cost: 0.477109, Accuracy 78.48%\n",
      "Epoch : 75000/100000 Cost: 0.476951, Accuracy 78.48%\n",
      "Epoch : 76000/100000 Cost: 0.476797, Accuracy 78.52%\n",
      "Epoch : 77000/100000 Cost: 0.476646, Accuracy 78.52%\n",
      "Epoch : 78000/100000 Cost: 0.476497, Accuracy 78.56%\n",
      "Epoch : 79000/100000 Cost: 0.476351, Accuracy 78.54%\n",
      "Epoch : 80000/100000 Cost: 0.476207, Accuracy 78.52%\n",
      "Epoch : 81000/100000 Cost: 0.476066, Accuracy 78.52%\n",
      "Epoch : 82000/100000 Cost: 0.475928, Accuracy 78.48%\n",
      "Epoch : 83000/100000 Cost: 0.475791, Accuracy 78.48%\n",
      "Epoch : 84000/100000 Cost: 0.475657, Accuracy 78.54%\n",
      "Epoch : 85000/100000 Cost: 0.475526, Accuracy 78.56%\n",
      "Epoch : 86000/100000 Cost: 0.475396, Accuracy 78.54%\n",
      "Epoch : 87000/100000 Cost: 0.475269, Accuracy 78.54%\n",
      "Epoch : 88000/100000 Cost: 0.475144, Accuracy 78.52%\n",
      "Epoch : 89000/100000 Cost: 0.475021, Accuracy 78.50%\n",
      "Epoch : 90000/100000 Cost: 0.474899, Accuracy 78.48%\n",
      "Epoch : 91000/100000 Cost: 0.474780, Accuracy 78.48%\n",
      "Epoch : 92000/100000 Cost: 0.474663, Accuracy 78.48%\n",
      "Epoch : 93000/100000 Cost: 0.474547, Accuracy 78.50%\n",
      "Epoch : 94000/100000 Cost: 0.474434, Accuracy 78.50%\n",
      "Epoch : 95000/100000 Cost: 0.474322, Accuracy 78.48%\n",
      "Epoch : 96000/100000 Cost: 0.474212, Accuracy 78.46%\n",
      "Epoch : 97000/100000 Cost: 0.474103, Accuracy 78.48%\n",
      "Epoch : 98000/100000 Cost: 0.473996, Accuracy 78.48%\n",
      "Epoch : 99000/100000 Cost: 0.473891, Accuracy 78.48%\n",
      "Epoch : 100000/100000 Cost: 0.473787, Accuracy 78.48%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 100000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = model(X_train)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "\n",
    "        print(f'Epoch : {epoch:4d}/{nb_epochs} Cost: {cost.item():.6f}, Accuracy {accuracy * 100:2.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-25\\AppData\\Local\\Temp\\ipykernel_9924\\2258457825.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pre_y = F.softmax(model(X_train[i])).max(0)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7835851367905268\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    pre_y = F.softmax(model(X_train[i])).max(0)[1]\n",
    "    if pre_y == y_train[i]:\n",
    "        num += 1\n",
    "print(num/X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
