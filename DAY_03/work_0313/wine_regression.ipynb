{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../../data/text/winequality-white.csv'\n",
    "wine_np = np.loadtxt(filename, delimiter=';', skiprows=1)\n",
    "wine_np.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_t1 = torch.from_numpy(wine_np)\n",
    "wine_t1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 11]), torch.float32, torch.Size([4898]), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = wine_t1[:, :-1].float()\n",
    "y_train = wine_t1[:, -1].float()\n",
    "X_train.shape, X_train.dtype, y_train.shape, y_train.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(X_train.shape[1], 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/5000 hypothesis: tensor([11.4649, -0.5585,  5.3495,  ...,  3.7441,  1.9926,  2.4251]) Cost: 18.235584\n",
      "Epoch   50/5000 hypothesis: tensor([10.4725, -0.3646,  4.7027,  ...,  3.1939,  1.8602,  2.1492]) Cost: 14.273854\n",
      "Epoch  100/5000 hypothesis: tensor([10.3186,  0.3229,  4.5641,  ...,  3.1906,  2.1997,  2.3239]) Cost: 11.745024\n",
      "Epoch  150/5000 hypothesis: tensor([10.1755,  0.9073,  4.4509,  ...,  3.1936,  2.4950,  2.4805]) Cost: 9.890283\n",
      "Epoch  200/5000 hypothesis: tensor([10.0417,  1.4047,  4.3592,  ...,  3.2018,  2.7529,  2.6215]) Cost: 8.518326\n",
      "Epoch  250/5000 hypothesis: tensor([9.9161, 1.8285, 4.2856,  ..., 3.2143, 2.9790, 2.7491]) Cost: 7.492657\n",
      "Epoch  300/5000 hypothesis: tensor([9.7977, 2.1901, 4.2271,  ..., 3.2303, 3.1781, 2.8654]) Cost: 6.715867\n",
      "Epoch  350/5000 hypothesis: tensor([9.6857, 2.4991, 4.1813,  ..., 3.2492, 3.3541, 2.9718]) Cost: 6.118422\n",
      "Epoch  400/5000 hypothesis: tensor([9.5794, 2.7635, 4.1462,  ..., 3.2703, 3.5106, 3.0697]) Cost: 5.650659\n",
      "Epoch  450/5000 hypothesis: tensor([9.4781, 2.9903, 4.1201,  ..., 3.2933, 3.6503, 3.1603]) Cost: 5.277098\n",
      "Epoch  500/5000 hypothesis: tensor([9.3813, 3.1852, 4.1016,  ..., 3.3177, 3.7758, 3.2446]) Cost: 4.972365\n",
      "Epoch  550/5000 hypothesis: tensor([9.2886, 3.3530, 4.0893,  ..., 3.3431, 3.8890, 3.3233]) Cost: 4.718298\n",
      "Epoch  600/5000 hypothesis: tensor([9.1995, 3.4980, 4.0822,  ..., 3.3694, 3.9918, 3.3972]) Cost: 4.501882\n",
      "Epoch  650/5000 hypothesis: tensor([9.1139, 3.6236, 4.0795,  ..., 3.3962, 4.0855, 3.4668]) Cost: 4.313772\n",
      "Epoch  700/5000 hypothesis: tensor([9.0313, 3.7327, 4.0805,  ..., 3.4235, 4.1716, 3.5328]) Cost: 4.147245\n",
      "Epoch  750/5000 hypothesis: tensor([8.9516, 3.8279, 4.0845,  ..., 3.4510, 4.2509, 3.5954]) Cost: 3.997449\n",
      "Epoch  800/5000 hypothesis: tensor([8.8744, 3.9113, 4.0909,  ..., 3.4785, 4.3244, 3.6551]) Cost: 3.860868\n",
      "Epoch  850/5000 hypothesis: tensor([8.7997, 3.9845, 4.0994,  ..., 3.5061, 4.3930, 3.7121]) Cost: 3.734941\n",
      "Epoch  900/5000 hypothesis: tensor([8.7273, 4.0492, 4.1096,  ..., 3.5335, 4.4571, 3.7669]) Cost: 3.617790\n",
      "Epoch  950/5000 hypothesis: tensor([8.6571, 4.1065, 4.1212,  ..., 3.5608, 4.5174, 3.8195]) Cost: 3.508026\n",
      "Epoch 1000/5000 hypothesis: tensor([8.5888, 4.1576, 4.1338,  ..., 3.5879, 4.5743, 3.8701]) Cost: 3.404614\n",
      "Epoch 1050/5000 hypothesis: tensor([8.5225, 4.2034, 4.1474,  ..., 3.6146, 4.6283, 3.9190]) Cost: 3.306769\n",
      "Epoch 1100/5000 hypothesis: tensor([8.4579, 4.2447, 4.1616,  ..., 3.6410, 4.6796, 3.9663]) Cost: 3.213888\n",
      "Epoch 1150/5000 hypothesis: tensor([8.3951, 4.2820, 4.1764,  ..., 3.6671, 4.7286, 4.0121]) Cost: 3.125500\n",
      "Epoch 1200/5000 hypothesis: tensor([8.3339, 4.3160, 4.1915,  ..., 3.6928, 4.7754, 4.0565]) Cost: 3.041229\n",
      "Epoch 1250/5000 hypothesis: tensor([8.2743, 4.3471, 4.2070,  ..., 3.7181, 4.8204, 4.0996]) Cost: 2.960769\n",
      "Epoch 1300/5000 hypothesis: tensor([8.2162, 4.3757, 4.2227,  ..., 3.7429, 4.8636, 4.1416]) Cost: 2.883866\n",
      "Epoch 1350/5000 hypothesis: tensor([8.1595, 4.4021, 4.2385,  ..., 3.7673, 4.9053, 4.1823]) Cost: 2.810302\n",
      "Epoch 1400/5000 hypothesis: tensor([8.1043, 4.4267, 4.2543,  ..., 3.7913, 4.9456, 4.2220]) Cost: 2.739890\n",
      "Epoch 1450/5000 hypothesis: tensor([8.0504, 4.4496, 4.2702,  ..., 3.8148, 4.9845, 4.2607]) Cost: 2.672464\n",
      "Epoch 1500/5000 hypothesis: tensor([7.9978, 4.4711, 4.2860,  ..., 3.8379, 5.0222, 4.2985]) Cost: 2.607874\n",
      "Epoch 1550/5000 hypothesis: tensor([7.9465, 4.4913, 4.3018,  ..., 3.8606, 5.0588, 4.3353]) Cost: 2.545985\n",
      "Epoch 1600/5000 hypothesis: tensor([7.8964, 4.5104, 4.3175,  ..., 3.8828, 5.0943, 4.3712]) Cost: 2.486672\n",
      "Epoch 1650/5000 hypothesis: tensor([7.8475, 4.5285, 4.3330,  ..., 3.9046, 5.1289, 4.4062]) Cost: 2.429818\n",
      "Epoch 1700/5000 hypothesis: tensor([7.7997, 4.5458, 4.3484,  ..., 3.9259, 5.1625, 4.4405]) Cost: 2.375315\n",
      "Epoch 1750/5000 hypothesis: tensor([7.7531, 4.5623, 4.3636,  ..., 3.9468, 5.1952, 4.4739]) Cost: 2.323061\n",
      "Epoch 1800/5000 hypothesis: tensor([7.7076, 4.5781, 4.3787,  ..., 3.9672, 5.2270, 4.5066]) Cost: 2.272953\n",
      "Epoch 1850/5000 hypothesis: tensor([7.6631, 4.5932, 4.3936,  ..., 3.9873, 5.2581, 4.5386]) Cost: 2.224910\n",
      "Epoch 1900/5000 hypothesis: tensor([7.6197, 4.6077, 4.4083,  ..., 4.0069, 5.2884, 4.5698]) Cost: 2.178839\n",
      "Epoch 1950/5000 hypothesis: tensor([7.5773, 4.6217, 4.4227,  ..., 4.0261, 5.3180, 4.6004]) Cost: 2.134657\n",
      "Epoch 2000/5000 hypothesis: tensor([7.5359, 4.6353, 4.4370,  ..., 4.0449, 5.3469, 4.6303]) Cost: 2.092286\n",
      "Epoch 2050/5000 hypothesis: tensor([7.4954, 4.6484, 4.4511,  ..., 4.0634, 5.3750, 4.6595]) Cost: 2.051649\n",
      "Epoch 2100/5000 hypothesis: tensor([7.4559, 4.6610, 4.4649,  ..., 4.0814, 5.4026, 4.6881]) Cost: 2.012674\n",
      "Epoch 2150/5000 hypothesis: tensor([7.4173, 4.6733, 4.4786,  ..., 4.0990, 5.4295, 4.7161]) Cost: 1.975292\n",
      "Epoch 2200/5000 hypothesis: tensor([7.3795, 4.6852, 4.4920,  ..., 4.1163, 5.4557, 4.7434]) Cost: 1.939436\n",
      "Epoch 2250/5000 hypothesis: tensor([7.3427, 4.6967, 4.5052,  ..., 4.1332, 5.4814, 4.7702]) Cost: 1.905043\n",
      "Epoch 2300/5000 hypothesis: tensor([7.3067, 4.7080, 4.5182,  ..., 4.1497, 5.5065, 4.7964]) Cost: 1.872053\n",
      "Epoch 2350/5000 hypothesis: tensor([7.2715, 4.7189, 4.5311,  ..., 4.1659, 5.5311, 4.8221]) Cost: 1.840406\n",
      "Epoch 2400/5000 hypothesis: tensor([7.2372, 4.7295, 4.5437,  ..., 4.1818, 5.5551, 4.8471]) Cost: 1.810048\n",
      "Epoch 2450/5000 hypothesis: tensor([7.2036, 4.7399, 4.5560,  ..., 4.1973, 5.5785, 4.8717]) Cost: 1.780925\n",
      "Epoch 2500/5000 hypothesis: tensor([7.1708, 4.7500, 4.5682,  ..., 4.2124, 5.6015, 4.8957]) Cost: 1.752986\n",
      "Epoch 2550/5000 hypothesis: tensor([7.1388, 4.7598, 4.5802,  ..., 4.2273, 5.6239, 4.9192]) Cost: 1.726181\n",
      "Epoch 2600/5000 hypothesis: tensor([7.1075, 4.7694, 4.5920,  ..., 4.2418, 5.6459, 4.9423]) Cost: 1.700464\n",
      "Epoch 2650/5000 hypothesis: tensor([7.0769, 4.7787, 4.6036,  ..., 4.2560, 5.6673, 4.9648]) Cost: 1.675790\n",
      "Epoch 2700/5000 hypothesis: tensor([7.0470, 4.7878, 4.6150,  ..., 4.2700, 5.6883, 4.9868]) Cost: 1.652116\n",
      "Epoch 2750/5000 hypothesis: tensor([7.0179, 4.7967, 4.6262,  ..., 4.2836, 5.7089, 5.0084]) Cost: 1.629400\n",
      "Epoch 2800/5000 hypothesis: tensor([6.9893, 4.8054, 4.6373,  ..., 4.2969, 5.7289, 5.0296]) Cost: 1.607605\n",
      "Epoch 2850/5000 hypothesis: tensor([6.9615, 4.8138, 4.6481,  ..., 4.3099, 5.7486, 5.0502]) Cost: 1.586689\n",
      "Epoch 2900/5000 hypothesis: tensor([6.9343, 4.8221, 4.6588,  ..., 4.3227, 5.7678, 5.0705]) Cost: 1.566619\n",
      "Epoch 2950/5000 hypothesis: tensor([6.9077, 4.8301, 4.6692,  ..., 4.3352, 5.7866, 5.0903]) Cost: 1.547358\n",
      "Epoch 3000/5000 hypothesis: tensor([6.8817, 4.8380, 4.6795,  ..., 4.3474, 5.8050, 5.1097]) Cost: 1.528873\n",
      "Epoch 3050/5000 hypothesis: tensor([6.8563, 4.8457, 4.6897,  ..., 4.3593, 5.8230, 5.1287]) Cost: 1.511134\n",
      "Epoch 3100/5000 hypothesis: tensor([6.8315, 4.8532, 4.6996,  ..., 4.3710, 5.8406, 5.1472]) Cost: 1.494107\n",
      "Epoch 3150/5000 hypothesis: tensor([6.8073, 4.8605, 4.7094,  ..., 4.3825, 5.8578, 5.1654]) Cost: 1.477766\n",
      "Epoch 3200/5000 hypothesis: tensor([6.7837, 4.8677, 4.7191,  ..., 4.3937, 5.8747, 5.1832]) Cost: 1.462081\n",
      "Epoch 3250/5000 hypothesis: tensor([6.7605, 4.8747, 4.7285,  ..., 4.4047, 5.8911, 5.2006]) Cost: 1.447025\n",
      "Epoch 3300/5000 hypothesis: tensor([6.7380, 4.8815, 4.7378,  ..., 4.4154, 5.9073, 5.2177]) Cost: 1.432572\n",
      "Epoch 3350/5000 hypothesis: tensor([6.7159, 4.8882, 4.7470,  ..., 4.4259, 5.9230, 5.2344]) Cost: 1.418698\n",
      "Epoch 3400/5000 hypothesis: tensor([6.6943, 4.8947, 4.7560,  ..., 4.4362, 5.9385, 5.2507]) Cost: 1.405379\n",
      "Epoch 3450/5000 hypothesis: tensor([6.6733, 4.9011, 4.7648,  ..., 4.4462, 5.9535, 5.2667]) Cost: 1.392591\n",
      "Epoch 3500/5000 hypothesis: tensor([6.6527, 4.9073, 4.7735,  ..., 4.4561, 5.9683, 5.2824]) Cost: 1.380314\n",
      "Epoch 3550/5000 hypothesis: tensor([6.6326, 4.9134, 4.7821,  ..., 4.4657, 5.9827, 5.2977]) Cost: 1.368527\n",
      "Epoch 3600/5000 hypothesis: tensor([6.6130, 4.9193, 4.7905,  ..., 4.4751, 5.9969, 5.3127]) Cost: 1.357208\n",
      "Epoch 3650/5000 hypothesis: tensor([6.5938, 4.9251, 4.7988,  ..., 4.4844, 6.0107, 5.3274]) Cost: 1.346340\n",
      "Epoch 3700/5000 hypothesis: tensor([6.5751, 4.9308, 4.8069,  ..., 4.4934, 6.0242, 5.3418]) Cost: 1.335903\n",
      "Epoch 3750/5000 hypothesis: tensor([6.5568, 4.9363, 4.8149,  ..., 4.5022, 6.0374, 5.3559]) Cost: 1.325880\n",
      "Epoch 3800/5000 hypothesis: tensor([6.5389, 4.9417, 4.8228,  ..., 4.5109, 6.0503, 5.3696]) Cost: 1.316254\n",
      "Epoch 3850/5000 hypothesis: tensor([6.5214, 4.9470, 4.8305,  ..., 4.5194, 6.0630, 5.3831]) Cost: 1.307008\n",
      "Epoch 3900/5000 hypothesis: tensor([6.5043, 4.9522, 4.8381,  ..., 4.5277, 6.0754, 5.3963]) Cost: 1.298128\n",
      "Epoch 3950/5000 hypothesis: tensor([6.4877, 4.9572, 4.8456,  ..., 4.5358, 6.0875, 5.4092]) Cost: 1.289598\n",
      "Epoch 4000/5000 hypothesis: tensor([6.4714, 4.9621, 4.8530,  ..., 4.5437, 6.0993, 5.4219]) Cost: 1.281404\n",
      "Epoch 4050/5000 hypothesis: tensor([6.4555, 4.9669, 4.8602,  ..., 4.5515, 6.1109, 5.4342]) Cost: 1.273532\n",
      "Epoch 4100/5000 hypothesis: tensor([6.4399, 4.9717, 4.8673,  ..., 4.5591, 6.1222, 5.4463]) Cost: 1.265968\n",
      "Epoch 4150/5000 hypothesis: tensor([6.4247, 4.9762, 4.8743,  ..., 4.5665, 6.1333, 5.4582]) Cost: 1.258702\n",
      "Epoch 4200/5000 hypothesis: tensor([6.4099, 4.9807, 4.8812,  ..., 4.5738, 6.1441, 5.4698]) Cost: 1.251720\n",
      "Epoch 4250/5000 hypothesis: tensor([6.3954, 4.9851, 4.8880,  ..., 4.5809, 6.1547, 5.4812]) Cost: 1.245010\n",
      "Epoch 4300/5000 hypothesis: tensor([6.3813, 4.9894, 4.8946,  ..., 4.5879, 6.1650, 5.4923]) Cost: 1.238562\n",
      "Epoch 4350/5000 hypothesis: tensor([6.3675, 4.9936, 4.9012,  ..., 4.5948, 6.1752, 5.5032]) Cost: 1.232365\n",
      "Epoch 4400/5000 hypothesis: tensor([6.3540, 4.9977, 4.9076,  ..., 4.6015, 6.1851, 5.5138]) Cost: 1.226408\n",
      "Epoch 4450/5000 hypothesis: tensor([6.3408, 5.0017, 4.9140,  ..., 4.6080, 6.1947, 5.5242]) Cost: 1.220683\n",
      "Epoch 4500/5000 hypothesis: tensor([6.3279, 5.0056, 4.9202,  ..., 4.6144, 6.2042, 5.5344]) Cost: 1.215179\n",
      "Epoch 4550/5000 hypothesis: tensor([6.3153, 5.0094, 4.9263,  ..., 4.6207, 6.2135, 5.5444]) Cost: 1.209887\n",
      "Epoch 4600/5000 hypothesis: tensor([6.3030, 5.0131, 4.9324,  ..., 4.6268, 6.2225, 5.5542]) Cost: 1.204799\n",
      "Epoch 4650/5000 hypothesis: tensor([6.2910, 5.0168, 4.9383,  ..., 4.6329, 6.2314, 5.5638]) Cost: 1.199907\n",
      "Epoch 4700/5000 hypothesis: tensor([6.2793, 5.0203, 4.9441,  ..., 4.6388, 6.2400, 5.5731]) Cost: 1.195203\n",
      "Epoch 4750/5000 hypothesis: tensor([6.2678, 5.0238, 4.9499,  ..., 4.6445, 6.2485, 5.5823]) Cost: 1.190679\n",
      "Epoch 4800/5000 hypothesis: tensor([6.2566, 5.0272, 4.9555,  ..., 4.6502, 6.2568, 5.5912]) Cost: 1.186328\n",
      "Epoch 4850/5000 hypothesis: tensor([6.2457, 5.0305, 4.9611,  ..., 4.6557, 6.2649, 5.6000]) Cost: 1.182142\n",
      "Epoch 4900/5000 hypothesis: tensor([6.2350, 5.0338, 4.9666,  ..., 4.6611, 6.2728, 5.6086]) Cost: 1.178115\n",
      "Epoch 4950/5000 hypothesis: tensor([6.2246, 5.0369, 4.9719,  ..., 4.6664, 6.2805, 5.6170]) Cost: 1.174241\n",
      "Epoch 5000/5000 hypothesis: tensor([6.2144, 5.0400, 4.9772,  ..., 4.6716, 6.2881, 5.6253]) Cost: 1.170514\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = model(X_train)\n",
    "\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{nb_epochs} hypothesis: {hypothesis.squeeze().detach()} Cost: {cost.item():.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7669])\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    error += abs(y_train[i] - model(X_train[i]))\n",
    "print((error/X_train.shape[0]).detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
