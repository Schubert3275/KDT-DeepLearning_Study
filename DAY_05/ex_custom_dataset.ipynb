{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader 살표보기\n",
    "\n",
    "-   Pytorch에서 배치 크기만큼 데이터를 조절하기 위한 메카니즘\n",
    "-   Dataset : 사용 데이터를 기반으로 사용자 정의 클래스 작성\n",
    "-   DataLoader : 지정된 Dataset에서 지정된 batch size만큼 피쳐와 타겟을 추출하여 전달\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 모듈 로딩 및 데이터 준비 <hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.1\n"
     ]
    }
   ],
   "source": [
    "### 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data = > torch.Size([5, 3]), 2D\n",
      "y_data = > torch.Size([5, 1]), 2D\n"
     ]
    }
   ],
   "source": [
    "### 데이터 준비\n",
    "\n",
    "x_data = torch.IntTensor(\n",
    "    [[10, 20, 30], [20, 30, 40], [30, 40, 50], [40, 50, 60], [50, 60, 70]]\n",
    ")\n",
    "y_data = torch.IntTensor([[20], [30], [40], [50], [60]])\n",
    "\n",
    "print(f\"x_data = > {x_data.shape}, {x_data.ndim}D\")\n",
    "print(f\"y_data = > {y_data.shape}, {y_data.ndim}D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 데이터셋 생성 <hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2-1] TensorDataset 활용 : Dataset의 sub_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset 클래스 로딩\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1e4bc0ab8e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(\n",
    "    x_data, y_data\n",
    ")  # x_data, y_data shape[0]이 다르면 dataset 생성 안 됨\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 20, 30],\n",
       "         [20, 30, 40],\n",
       "         [30, 40, 50],\n",
       "         [40, 50, 60],\n",
       "         [50, 60, 70]], dtype=torch.int32),\n",
       " tensor([[20],\n",
       "         [30],\n",
       "         [40],\n",
       "         [50],\n",
       "         [60]], dtype=torch.int32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10, 20, 30], dtype=torch.int32), tensor([20], dtype=torch.int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### __getitem__() 메서드 호출\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2-2] 사용자정의 데이터셋 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "### 데이터 준비\n",
    "filename = \"../data/text/iris.csv\"\n",
    "\n",
    "irisDF = pd.read_csv(filename)\n",
    "irisDF.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisNP = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=(0, 1, 2, 3))\n",
    "irisNP[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, numpy.ndarray, 'DataFrame', 'ndarray')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터의 타입 체크\n",
    "type(irisDF), type(irisNP), irisDF.__class__.__name__, irisNP.__class__.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF\n"
     ]
    }
   ],
   "source": [
    "if irisDF.__class__.__name__ == \"DataFrame\":\n",
    "    print(\"DF\")\n",
    "else:\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(irisDF, pd.DataFrame), isinstance(irisNP, pd.DataFrame), isinstance(\n",
    "    irisNP, np.ndarray\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance([10], list), isinstance({\"A\": 22}, list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용자정의 DataSet 클래스\n",
    "# - 데이터의 Tensor 변환\n",
    "class DLDataset(Dataset):\n",
    "    # 초기화 콜백함수(callback function)\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # x,y 데이터 ==> ndarray\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data\n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data\n",
    "\n",
    "        # ndarray ==> tensor\n",
    "        self.feature = torch.tensor(x_data)\n",
    "        self.target = torch.tensor(y_data)\n",
    "\n",
    "    # 데이터셋의 갯수 체크 콜백함수(callback function)\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "\n",
    "    # 특정 인덱스 데이터 + 라벨 반환 콜백함수(callback function)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), 2D\n",
      "targetDF  => (150,), 1D\n"
     ]
    }
   ],
   "source": [
    "## 피쳐와 라벨로 분리\n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetDF = irisDF[irisDF.columns[-1]]\n",
    "\n",
    "print(f\"featureDF => {featureDF.shape}, {featureDF.ndim}D\")\n",
    "print(f\"targetDF  => {targetDF.shape}, {targetDF.ndim}D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1) 2\n"
     ]
    }
   ],
   "source": [
    "# object 타입 타겟 ===> int 타입 타겟 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "targetNP = LabelEncoder().fit_transform(targetDF)\n",
    "targetNP = targetNP.reshape(-1, 1)\n",
    "\n",
    "print(targetNP.shape, targetNP.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성 -> DF, NP\n",
    "my_dataset = DLDataset(featureDF, targetNP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([5.1000, 3.5000, 1.4000, 0.2000], dtype=torch.float64),\n",
       "  tensor([0], dtype=torch.int32)),\n",
       " sepal_length    5.1\n",
       " sepal_width     3.5\n",
       " petal_length    1.4\n",
       " petal_width     0.2\n",
       " Name: 0, dtype: float64,\n",
       " 'setosa')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0], featureDF.iloc[0], targetDF[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000], dtype=torch.float64),\n",
       " tensor([0], dtype=torch.int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 생성 -> NP, NP\n",
    "my_dataset2 = DLDataset(irisNP, targetNP)\n",
    "my_dataset2[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
